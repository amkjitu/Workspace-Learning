{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "492d1bb9",
   "metadata": {},
   "source": [
    "# Bangla Doctor-Patient Conversation Summarization\n",
    "\n",
    "This notebook implements a pipeline to summarize Bangla doctor-patient conversations by extracting key entities like symptoms, medications, and duration, and then generating a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e671c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup: Install necessary libraries\n",
    "# Ensure you have these libraries installed. Uncomment the line below to install if needed.\n",
    "%pip install transformers torch bnlp_toolkit spacy\n",
    "%python -m spacy download en_core_web_sm # Example for spaCy, Bangla models might need different handling or custom setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59951df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from bnlp import BasicTokenizer, NER as BNLP_NER\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "# For Bangla-BERT NER (optional, requires fine-tuning or specific pre-trained model for medical entities)\n",
    "# from transformers import AutoModelForTokenClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a0905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Input: Example Bangla Doctor-Patient Conversation\n",
    "conversation_text = \"\"\"রোগী: ডাক্তার সাহেব, আমার গত তিন দিন ধরে খুব জ্বর ও শরীরে ব্যথা অনুভব করছি। সাথে ঠান্ডাও লেগেছে।\n",
    "ডাক্তার: আচ্ছা, তাপমাত্রা মেপেছেন? অন্য কোনো উপসর্গ আছে, যেমন কাশি বা গলা ব্যথা?\n",
    "রোগী: হ্যাঁ, তাপমাত্রা ১০২ ডিগ্রি ফারেনহাইট। হালকা কাশিও আছে। গলা ব্যথা নেই।\n",
    "ডাক্তার: আমি আপনাকে কিছু ওষুধ দিচ্ছি। প্যারাসিটামল ৫০০মিগ্রা দিনে তিনবার খাবেন, ভরা পেটে। সাথে একটি অ্যান্টিহিস্টামিন দিচ্ছি, রাতে একটা করে খাবেন, সাত দিন। প্রচুর পানি পান করবেন ও বিশ্রাম নেবেন।\n",
    "রোগী: ধন্যবাদ ডাক্তার সাহেব।\n",
    "\"\"\"\n",
    "\n",
    "print(\"Original Conversation:\")\n",
    "print(conversation_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629256e8",
   "metadata": {},
   "source": [
    "## 3. Preprocessing & Named Entity Recognition (NER)\n",
    "\n",
    "We'll use BNLP for tokenization and its pre-trained NER model. For more advanced NER, fine-tuning a model like Bangla-BERT on medical conversations would be beneficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa517970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BNLP tools\n",
    "tokenizer = BasicTokenizer()\n",
    "bnlp_ner = BNLP_NER()\n",
    "\n",
    "# Tokenize the conversation (BNLP NER often works on raw text, but tokenization can be a separate step)\n",
    "tokens = tokenizer.tokenize(conversation_text)\n",
    "# print(\"\\\\nTokenized Text:\")\n",
    "# print(tokens) # BNLP NER takes raw text\n",
    "\n",
    "# Perform NER using BNLP\n",
    "# BNLP's NER might not have specific \"SYMPTOM\", \"MEDICATION\", \"DURATION\" tags out-of-the-box for medical domain.\n",
    "# It typically identifies general entities like Person (PER), Location (LOC), Organization (ORG), Date (DATE), Time (TIME), Money (MONEY), Percent (PERCENT).\n",
    "# We will need to map or infer these from the general tags or train a custom NER model.\n",
    "# For this example, we'll try to extract based on keywords and general tags if direct medical tags aren't present.\n",
    "\n",
    "print(\"\\\\nBNLP NER Output (General Entities):\")\n",
    "entities_bnlp = bnlp_ner.tag(conversation_text)\n",
    "print(entities_bnlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3415a4c",
   "metadata": {},
   "source": [
    "### 3.1. Custom Keyword-Based Extraction (Simpler Approach for Demo)\n",
    "Since BNLP's default NER might not directly give us \"SYMPTOM\", \"MEDICATION\", \"DURATION\", we'll use a keyword-based approach for this demonstration. For a robust solution, a custom-trained NER model is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d330637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keywords for extraction (this is a very basic approach)\n",
    "symptom_keywords = [\"জ্বর\", \"ব্যথা\", \"কাশি\", \"ঠান্ডা\", \"গলা ব্যথা\", \"মাথাব্যথা\"]\n",
    "medication_keywords = [\"প্যারাসিটামল\", \"অ্যান্টিহিস্টামিন\", \"নাপা\", \"এসপিরিন\"] # Add more as needed\n",
    "duration_keywords = [\"দিন\", \"সপ্তাহ\", \"মাস\"] # Often associated with numbers\n",
    "\n",
    "extracted_symptoms = []\n",
    "extracted_medications = []\n",
    "extracted_durations = []\n",
    "\n",
    "# Simple keyword spotting (can be improved with regex and context analysis)\n",
    "# This is a placeholder for a more sophisticated NER/Keyword extraction\n",
    "words = conversation_text.replace(\\'\\\\n\\', \\' \\').split(\\' \\') # Basic word splitting\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    # Clean the word\n",
    "    cleaned_word = word.strip(\\',.?!\\')\n",
    "    \n",
    "    if cleaned_word in symptom_keywords:\n",
    "        extracted_symptoms.append(cleaned_word)\n",
    "    \n",
    "    if cleaned_word in medication_keywords:\n",
    "        # Try to capture dosage if available (e.g., \"৫০০মিগ্রা\")\n",
    "        med_info = cleaned_word\n",
    "        if i + 1 < len(words) and (\"মিগ্রা\" in words[i+1] or \"mg\" in words[i+1].lower()):\n",
    "            med_info += \" \" + words[i+1]\n",
    "        extracted_medications.append(med_info)\n",
    "        \n",
    "    if cleaned_word in duration_keywords:\n",
    "        # Try to capture the number before \"দিন\", \"সপ্তাহ\", etc.\n",
    "        if i > 0 and words[i-1].isdigit(): # Basic check for a preceding number\n",
    "            extracted_durations.append(words[i-1] + \" \" + cleaned_word)\n",
    "        elif i > 0 and words[i-1] == \"এক\": # Handle \"এক দিন\"\n",
    "             extracted_durations.append(\"এক \" + cleaned_word)\n",
    "        elif i > 0 and words[i-1] == \"দুই\":\n",
    "             extracted_durations.append(\"দুই \" + cleaned_word)\n",
    "        elif i > 0 and words[i-1] == \"তিন\":\n",
    "             extracted_durations.append(\"তিন \" + cleaned_word)\n",
    "        # This can be made more robust with number parsing in Bangla\n",
    "        # For now, let's also add durations found by BNLP if they are DATEs\n",
    "        \n",
    "# Add durations found by BNLP if tagged as DATE (often includes durations)\n",
    "for entity, tag in entities_bnlp:\n",
    "    if tag == \"DATE\": # BNLP uses DATE for time expressions like \"তিন দিন\"\n",
    "        # Check if it contains duration keywords\n",
    "        if any(d_keyword in entity for d_keyword in duration_keywords):\n",
    "             if entity not in extracted_durations: # Avoid duplicates\n",
    "                extracted_durations.append(entity)\n",
    "\n",
    "\n",
    "# Remove duplicates\n",
    "extracted_symptoms = list(set(extracted_symptoms))\n",
    "extracted_medications = list(set(extracted_medications))\n",
    "extracted_durations = list(set(extracted_durations))\n",
    "\n",
    "\n",
    "print(\"\\\\n--- Extracted Information (Keyword-Based) ---\")\n",
    "print(f\"Symptoms: {extracted_symptoms}\")\n",
    "print(f\"Medications: {extracted_medications}\")\n",
    "print(f\"Durations: {extracted_durations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f76467",
   "metadata": {},
   "source": [
    "### 3.2. (Optional) NER using Hugging Face Transformers (e.g., Bangla-BERT)\n",
    "For better accuracy, you would fine-tune a model like `csebuetnlp/banglabert` on a Bangla medical NER dataset.\n",
    "If a pre-trained Bangla medical NER model is available, you can use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example placeholder for using a Hugging Face NER pipeline\n",
    "# # You would need a model fine-tuned for Bangla medical NER.\n",
    "# # For instance, if 'some-bangla-medical-ner-model' existed on Hugging Face Hub:\n",
    "# try:\n",
    "#     ner_pipeline_hf = pipeline(\"ner\", model=\"sagorsarker/bangla-bert-ner\", tokenizer=\"sagorsarker/bangla-bert-ner\", grouped_entities=True)\n",
    "#     # The model above is a general Bangla NER model, it might not have specific medical entity types.\n",
    "#     # It might identify entities like B-PER, I-PER, B-LOC, I-LOC, B-ORG, I-ORG, etc.\n",
    "#     # You would need to map these or use a model specifically trained for SYMPTOM, MEDICATION, DURATION.\n",
    "#     hf_entities = ner_pipeline_hf(conversation_text)\n",
    "#     print(\"\\\\n--- Hugging Face NER Output (Example with sagorsarker/bangla-bert-ner) ---\")\n",
    "#     print(hf_entities)\n",
    "\n",
    "#     # Process hf_entities to extract symptoms, medications, durations based on its entity types\n",
    "#     # This part is highly dependent on the specific model's output and entity schema.\n",
    "#     # e.g., if it had a 'MED' tag:\n",
    "#     # extracted_medications_hf = [entity['word'] for entity in hf_entities if entity['entity_group'] == 'MED']\n",
    "#     # print(f\"Medications (from HF NER): {extracted_medications_hf}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"Could not load Hugging Face NER model. This is an optional step. Error: {e}\")\n",
    "#     print(\"Skipping Hugging Face NER.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c807b6b",
   "metadata": {},
   "source": [
    "## 4. Conversational Summarization\n",
    "We will use a pre-trained sequence-to-sequence model (like mT5) for summarization. We'll create a prompt from the extracted entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input for the summarization model\n",
    "# Using the keyword-based extracted entities for this demo\n",
    "if not extracted_symptoms and not extracted_medications and not extracted_durations:\n",
    "    summary_input_text = \"রোগীর সাধারণ কথোপকথন।\" # Fallback if no entities extracted\n",
    "else:\n",
    "    summary_input_text = \"রোগীর লক্ষণসমূহ: \" + \", \".join(extracted_symptoms) + \\\n",
    "                         \"। পরামর্শকৃত ঔষধ: \" + \", \".join(extracted_medications) + \\\n",
    "                         \"। সময়কাল: \" + \", \".join(extracted_durations) + \"।\"\n",
    "\n",
    "print(\"\\\\n--- Input for Summarization Model ---\")\n",
    "print(summary_input_text)\n",
    "\n",
    "# Load a pre-trained summarization model (e.g., mT5 small for multilingual capabilities)\n",
    "# Using a smaller model for quicker execution in a demo.\n",
    "# For better Bangla summarization, a model fine-tuned on Bangla text or medical summaries would be ideal.\n",
    "summarizer_model_name = \"google/mt5-small\" \n",
    "try:\n",
    "    summarizer_tokenizer = AutoTokenizer.from_pretrained(summarizer_model_name)\n",
    "    summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(summarizer_model_name)\n",
    "    \n",
    "    # Create the summarization pipeline\n",
    "    summarization_pipeline = pipeline(\"summarization\", model=summarizer_model, tokenizer=summarizer_tokenizer)\n",
    "    \n",
    "    # Generate summary\n",
    "    # Prepending a task-specific prefix for mT5 if needed, e.g., \"summarize: \" or \"bangla summarize: \"\n",
    "    # For mT5, it's often trained with prefixes. Let's try without first.\n",
    "    # Max length of summary can be adjusted.\n",
    "    summary = summarization_pipeline(summary_input_text, max_length=100, min_length=10, do_sample=False)\n",
    "    \n",
    "    print(\"\\\\n--- Generated Summary (mT5-small) ---\")\n",
    "    print(summary[0]['summary_text'])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during summarization with {summarizer_model_name}: {e}\")\n",
    "    print(\"Please ensure the model name is correct and you have an internet connection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac99a0d8",
   "metadata": {},
   "source": [
    "## 5. Notes and Further Improvements\n",
    "*   **NER Model**: The keyword-based extraction is very basic. For robust performance, fine-tune a transformer model (like `csebuetnlp/banglabert` or `ai4bharat/indic-bert`) on a custom Bangla medical NER dataset. The dataset should have annotations for SYMPTOM, MEDICATION, DURATION, etc.\n",
    "*   **Summarization Model**: `google/mt5-small` is a general multilingual model. For higher quality summaries, fine-tuning mT5 or mBART (`facebook/mbart-large-cc25`) on Bangla conversational data, especially medical dialogues, is recommended.\n",
    "*   **Contextual Understanding**: More advanced techniques can be used to link symptoms to specific medications or durations if multiple are mentioned.\n",
    "*   **Preprocessing**: Advanced Bangla text normalization and cleaning can improve the performance of both NER and summarization.\n",
    "*   **BNLP NER Tags**: The default BNLP NER tags might not directly map to medical entities. You might need to analyze its output for `DATE`, `NUMBER`, `MISC` tags and apply rules, or extend BNLP with custom rules/models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
