{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"1020827e241ac87ffdf8e0f8762a6885bdc28fbc"},"source":["Import neccessary packages\n"]},{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import pickle\n","import cv2\n","from os import listdir\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.models import Sequential\n","from tensorflow.keras.layers import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation, Flatten, Dropout, Dense\n","from keras import backend as K\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import Adam\n","from keras.preprocessing import image\n","from keras.utils.image_utils import img_to_array\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":9,"metadata":{"_uuid":"7c3354a78e21a1a62ad0c4689d0ab3238fb760d4","trusted":true},"outputs":[],"source":["EPOCHS = 25\n","INIT_LR = 1e-3\n","BS = 32\n","default_image_size = tuple((256, 256))\n","image_size = 0\n","directory_root = '../dataset/RiceLeafs_Resized_1000/'\n","width = 256\n","height = 256\n","depth = 3\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"2bf7ac0a0b805946f844a48e55d5281403e53f57"},"source":["Function to convert images to array\n"]},{"cell_type":"code","execution_count":7,"metadata":{"_uuid":"c9c3e60b13ace6c8f3e54336e12f9970fde438a3","trusted":true},"outputs":[],"source":["def convert_image_to_array(image_dir):\n","    try:\n","        image = cv2.imread(image_dir)\n","        if image is not None:\n","            image = cv2.resize(image, default_image_size)\n","            return img_to_array(image)\n","        else:\n","            return np.array([])\n","    except Exception as e:\n","        print(f\"Error : {e}\")\n","        return None\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"24d42b87fad54a9556f78357ce673cc5152468c1"},"source":["Fetch images from directory\n"]},{"cell_type":"code","execution_count":10,"metadata":{"_uuid":"bb8d4c343314028f52ae3c3a840478a834a16c95","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Loading images ...\n","[INFO] Processing BrownSpot ...\n","[INFO] Processing Healthy ...\n","[INFO] Processing Hispa ...\n","[INFO] Processing LeafBlast ...\n","[INFO] Processing BrownSpot ...\n","[INFO] Processing Healthy ...\n","[INFO] Processing Hispa ...\n","[INFO] Processing LeafBlast ...\n","[INFO] Image loading completed\n"]}],"source":["image_list, label_list = [], []\n","try:\n","    print(\"[INFO] Loading images ...\")\n","    root_dir = listdir(directory_root)\n","    for directory in root_dir:\n","        # remove .DS_Store from list\n","        if directory == \".DS_Store\":\n","            root_dir.remove(directory)\n","\n","    for plant_folder in root_dir:\n","        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n","\n","        for disease_folder in plant_disease_folder_list:\n","            # remove .DS_Store from list\n","            if disease_folder == \".DS_Store\":\n","                plant_disease_folder_list.remove(disease_folder)\n","\n","        for plant_disease_folder in plant_disease_folder_list:\n","            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n","            plant_disease_image_list = listdir(\n","                f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n","\n","            for single_plant_disease_image in plant_disease_image_list:\n","                if single_plant_disease_image == \".DS_Store\":\n","                    plant_disease_image_list.remove(single_plant_disease_image)\n","\n","            for image in plant_disease_image_list[:200]:\n","                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n","                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n","                    image_list.append(convert_image_to_array(image_directory))\n","                    label_list.append(plant_disease_folder)\n","    print(\"[INFO] Image loading completed\")\n","except Exception as e:\n","    print(f\"Error : {e}\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"35c4b76d33e0263523e479657580104532f81d6e"},"source":["Get Size of Processed Image\n"]},{"cell_type":"code","execution_count":11,"metadata":{"_uuid":"6ee1ad9c422f112ec2862699b5c0f68b8d658123","trusted":true},"outputs":[],"source":["image_size = len(image_list)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"905b41b226f3fd82a88e67821eb42a07f24b31f7"},"source":["Transform Image Labels uisng [Scikit Learn](http://scikit-learn.org/)'s LabelBinarizer\n"]},{"cell_type":"code","execution_count":12,"metadata":{"_uuid":"904ff893fe14f5060dd9e7be2ccf96ec793597e5","trusted":true},"outputs":[],"source":["label_binarizer = LabelBinarizer()\n","image_labels = label_binarizer.fit_transform(label_list)\n","pickle.dump(label_binarizer, open('label_transform.pkl', 'wb'))\n","n_classes = len(label_binarizer.classes_)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"f860c29a1d714f06d25e6a0c5bca94739e5d24cc"},"source":["Print the classes\n"]},{"cell_type":"code","execution_count":13,"metadata":{"_uuid":"0f876397c40c3c8aa09772a92fd60481fc9ba268","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['BrownSpot' 'Healthy' 'Hispa' 'LeafBlast']\n"]}],"source":["print(label_binarizer.classes_)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"_uuid":"6cd9c977b3d164a5570a0c24fdd8624adb9d56b8","trusted":true},"outputs":[],"source":["np_image_list = np.array(image_list, dtype=np.float16) / 225.0\n"]},{"cell_type":"code","execution_count":15,"metadata":{"_uuid":"9f4829560fdfa218cee18c1cfb2eb9452ef180e5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Spliting data to train, test\n"]}],"source":["print(\"[INFO] Spliting data to train, test\")\n","x_train, x_test, y_train, y_test = train_test_split(\n","    np_image_list, image_labels, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"_uuid":"eec8afa64e676d52c814fc8e096955a60f13b6c5","trusted":true},"outputs":[],"source":["aug = ImageDataGenerator(\n","    rotation_range=25, width_shift_range=0.1,\n","    height_shift_range=0.1, shear_range=0.2,\n","    zoom_range=0.2, horizontal_flip=True,\n","    fill_mode=\"nearest\")\n"]},{"cell_type":"code","execution_count":17,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["model = Sequential()\n","inputShape = (height, width, depth)\n","chanDim = -1\n","if K.image_data_format() == \"channels_first\":\n","    inputShape = (depth, height, width)\n","    chanDim = 1\n","model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n","model.add(Activation(\"relu\"))\n","model.add(BatchNormalization(axis=chanDim))\n","model.add(MaxPooling2D(pool_size=(3, 3)))\n","model.add(Dropout(0.25))\n","model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(BatchNormalization(axis=chanDim))\n","model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(BatchNormalization(axis=chanDim))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Conv2D(128, (3, 3), padding=\"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(BatchNormalization(axis=chanDim))\n","model.add(Conv2D(128, (3, 3), padding=\"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(BatchNormalization(axis=chanDim))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(1024))\n","model.add(Activation(\"relu\"))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","model.add(Dense(n_classes))\n","model.add(Activation(\"softmax\"))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"53b13c03e4cea6dc2453a84e254b806ebeed2d99"},"source":["Model Summary\n"]},{"cell_type":"code","execution_count":18,"metadata":{"_uuid":"1e1523a834fbf872940171fbdefb3dcce2b5f31b","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 256, 256, 32)      896       \n","                                                                 \n"," activation (Activation)     (None, 256, 256, 32)      0         \n","                                                                 \n"," batch_normalization (BatchN  (None, 256, 256, 32)     128       \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 85, 85, 32)       0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 85, 85, 32)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 85, 85, 64)        18496     \n","                                                                 \n"," activation_1 (Activation)   (None, 85, 85, 64)        0         \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 85, 85, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 85, 85, 64)        36928     \n","                                                                 \n"," activation_2 (Activation)   (None, 85, 85, 64)        0         \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 85, 85, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 42, 42, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 42, 42, 64)        0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 42, 42, 128)       73856     \n","                                                                 \n"," activation_3 (Activation)   (None, 42, 42, 128)       0         \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 42, 42, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 42, 42, 128)       147584    \n","                                                                 \n"," activation_4 (Activation)   (None, 42, 42, 128)       0         \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 42, 42, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 21, 21, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_2 (Dropout)         (None, 21, 21, 128)       0         \n","                                                                 \n"," flatten (Flatten)           (None, 56448)             0         \n","                                                                 \n"," dense (Dense)               (None, 1024)              57803776  \n","                                                                 \n"," activation_5 (Activation)   (None, 1024)              0         \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 1024)             4096      \n"," hNormalization)                                                 \n","                                                                 \n"," dropout_3 (Dropout)         (None, 1024)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 4)                 4100      \n","                                                                 \n"," activation_6 (Activation)   (None, 4)                 0         \n","                                                                 \n","=================================================================\n","Total params: 58,091,396\n","Trainable params: 58,088,516\n","Non-trainable params: 2,880\n","_________________________________________________________________\n"]}],"source":["model.summary()\n"]},{"cell_type":"code","execution_count":20,"metadata":{"_uuid":"b21dffee32c325136b4ea23ac511049723f34a24","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] training network...\n"]}],"source":["opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n","# distribution\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","# train the network\n","print(\"[INFO] training network...\")\n"]},{"cell_type":"code","execution_count":22,"metadata":{"_uuid":"1a13efc5ded339fc3c0d9e61041e8ca555362db0","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","24/24 [==============================] - 231s 10s/step - loss: 0.8312 - accuracy: 0.3893 - val_loss: 0.6498 - val_accuracy: 0.1818\n","Epoch 2/25\n","24/24 [==============================] - 173s 7s/step - loss: 0.6433 - accuracy: 0.4513 - val_loss: 2.4407 - val_accuracy: 0.2727\n","Epoch 3/25\n","24/24 [==============================] - 175s 7s/step - loss: 0.5628 - accuracy: 0.4908 - val_loss: 2.4021 - val_accuracy: 0.3030\n","Epoch 4/25\n","24/24 [==============================] - 153s 6s/step - loss: 0.5510 - accuracy: 0.4803 - val_loss: 1.4757 - val_accuracy: 0.2121\n","Epoch 5/25\n","24/24 [==============================] - 153s 6s/step - loss: 0.5471 - accuracy: 0.4684 - val_loss: 1.1604 - val_accuracy: 0.2374\n","Epoch 6/25\n","24/24 [==============================] - 190s 8s/step - loss: 0.5365 - accuracy: 0.4674 - val_loss: 2.9737 - val_accuracy: 0.2424\n","Epoch 7/25\n","24/24 [==============================] - 162s 7s/step - loss: 0.5364 - accuracy: 0.4684 - val_loss: 0.7983 - val_accuracy: 0.2727\n","Epoch 8/25\n","24/24 [==============================] - 178s 7s/step - loss: 0.5359 - accuracy: 0.4724 - val_loss: 3.4353 - val_accuracy: 0.2424\n","Epoch 9/25\n","24/24 [==============================] - 167s 7s/step - loss: 0.5023 - accuracy: 0.4961 - val_loss: 5.8265 - val_accuracy: 0.2273\n","Epoch 10/25\n","24/24 [==============================] - 225s 9s/step - loss: 0.5063 - accuracy: 0.4829 - val_loss: 6.8940 - val_accuracy: 0.2778\n","Epoch 11/25\n","24/24 [==============================] - 154s 6s/step - loss: 0.4893 - accuracy: 0.5158 - val_loss: 6.7100 - val_accuracy: 0.2374\n","Epoch 12/25\n","24/24 [==============================] - 158s 7s/step - loss: 0.5072 - accuracy: 0.5091 - val_loss: 4.8745 - val_accuracy: 0.1970\n","Epoch 13/25\n","24/24 [==============================] - 165s 7s/step - loss: 0.4684 - accuracy: 0.5487 - val_loss: 5.4223 - val_accuracy: 0.1919\n","Epoch 14/25\n","24/24 [==============================] - 148s 6s/step - loss: 0.4825 - accuracy: 0.5197 - val_loss: 4.9227 - val_accuracy: 0.2879\n","Epoch 15/25\n","24/24 [==============================] - 157s 7s/step - loss: 0.4863 - accuracy: 0.5408 - val_loss: 2.0272 - val_accuracy: 0.3838\n","Epoch 16/25\n","24/24 [==============================] - 158s 7s/step - loss: 0.5246 - accuracy: 0.4934 - val_loss: 3.0090 - val_accuracy: 0.2222\n","Epoch 17/25\n","24/24 [==============================] - 152s 6s/step - loss: 0.4902 - accuracy: 0.5224 - val_loss: 1.4356 - val_accuracy: 0.3535\n","Epoch 18/25\n","24/24 [==============================] - 185s 8s/step - loss: 0.4821 - accuracy: 0.5276 - val_loss: 0.8462 - val_accuracy: 0.3283\n","Epoch 19/25\n","24/24 [==============================] - 207s 9s/step - loss: 0.4918 - accuracy: 0.5145 - val_loss: 1.4878 - val_accuracy: 0.2222\n","Epoch 20/25\n","24/24 [==============================] - 223s 9s/step - loss: 0.5483 - accuracy: 0.5092 - val_loss: 3.4292 - val_accuracy: 0.2424\n","Epoch 21/25\n","24/24 [==============================] - 185s 8s/step - loss: 0.5010 - accuracy: 0.5237 - val_loss: 0.7928 - val_accuracy: 0.2727\n","Epoch 22/25\n","24/24 [==============================] - 183s 8s/step - loss: 0.5126 - accuracy: 0.5329 - val_loss: 0.7009 - val_accuracy: 0.4040\n","Epoch 23/25\n","24/24 [==============================] - 176s 7s/step - loss: 0.4989 - accuracy: 0.5303 - val_loss: 0.5639 - val_accuracy: 0.4899\n","Epoch 24/25\n","24/24 [==============================] - 137s 6s/step - loss: 0.4883 - accuracy: 0.5526 - val_loss: 0.5676 - val_accuracy: 0.4949\n","Epoch 25/25\n","24/24 [==============================] - 136s 6s/step - loss: 0.4995 - accuracy: 0.5539 - val_loss: 0.4965 - val_accuracy: 0.4697\n"]}],"source":["history = model.fit(\n","    aug.flow(x_train, y_train, batch_size=BS),\n","    validation_data=(x_test, y_test),\n","    steps_per_epoch=len(x_train) // BS,\n","    epochs=EPOCHS, verbose=1\n",")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"1495fea08b37e4d4293f975ba30e6c1fc7a85ed9"},"source":["Plot the train and val curve\n"]},{"cell_type":"code","execution_count":23,"metadata":{"_uuid":"0af5e0f23657a4effc2d21cf8e840e81f42ec8e7","trusted":true},"outputs":[{"ename":"KeyError","evalue":"'acc'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39macc\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      2\u001b[0m val_acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m loss \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n","\u001b[1;31mKeyError\u001b[0m: 'acc'"]}],"source":["acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(acc) + 1)\n","# Train and validation accuracy\n","plt.plot(epochs, acc, 'b', label='Training accurarcy')\n","plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n","plt.title('Training and Validation accurarcy')\n","plt.legend()\n","\n","plt.figure()\n","# Train and validation loss\n","plt.plot(epochs, loss, 'b', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and Validation loss')\n","plt.legend()\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"9ca1a4489bd624c69a13cd37c0c2306ac8de55c2"},"source":["Model Accuracy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"bb44f3d0b7e2862bc7d1a032612ebfd48212c1fe","trusted":true},"outputs":[],"source":["print(\"[INFO] Calculating model accuracy\")\n","scores = model.evaluate(x_test, y_test)\n","print(f\"Test Accuracy: {scores[1]*100}\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"2a1f759db8afe933e62fe4cf8332cb303bb11be8"},"source":["Save model using Pickle\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"5cdf06adf492d79ed28fbdc36e02ad7489c7b33e","trusted":true},"outputs":[],"source":["# save the model to disk\n","print(\"[INFO] Saving model...\")\n","pickle.dump(model, open('cnn_model.pkl', 'wb'))\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
